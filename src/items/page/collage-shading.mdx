---
name: Collage shading system
tags: [itp-portfolio, mas-portfolio, 3d, code]
date:
  start: 2023-09-15
  end: 2024-05-17
home: work
slides:
  first: flower set.png
  rest:
  - bird map preview.png
  - bird still.png

priority: 2
---
import Box from 'src/layouts/Box.astro';
import { MuxPlayer } from "@mux/mux-player-astro";
import Img from 'src/components/Img.astro';

For the last few years I have been working alongside [Barb Meier](https://cs.brown.edu/people/bjm/) and my peers from her computer animation courses to make a short film, which partly takes place in an alternate world inspired by a child’s drawings. To create an effect of being inside a drawing, I designed and implemented a non-photorealistic shading system in Maya that renders <span class="lining">3D</span> objects as a collage of flat textures. The film is still in production, but here are a few early tests I made while working out the kinks:

<Box factor={2}>
  <MuxPlayer
    playbackId="Pg6hTFwPw802fDAhgQX5bHzFzBvTToN92wzgtsgHOiOM"
    metadata={{ video_title: 'Flower set' }}
    preferPlayback="mse"
    primaryColor="#e5e7eb"
    accentColor="#60889a"
  />
</Box>

<Box factor={2}>
  <MuxPlayer
    playbackId="5qd28rEfTNPf53B00obRUDWIzm4Jo1jzLya9yqT4gD8I"
    metadata={{ video_title: 'Bird' }}
    preferPlayback="mse"
    primaryColor="#e5e7eb"
    accentColor="#60889a"
  />
</Box>

*Models, animation, and most of the textures are by my friends in Advanced Animation Production at Brown.*

## Behind the scenes

In normal <span class="lining">3D</span> rendering, textures wrap around objects and follow the rules of perspective:

<Box factor={.4}>
  <Img src='regular cylinder.png'/>
</Box>

My collage shading system does not do this; rather, textures stay flat on the screen, regardless of how the surface is shaped or how you’re looking at it:

<Box factor={.4}>
  <Img src='collage cylinder.png'/>
</Box>

These flat textures move, rotate, and scale to follow the surface as it moves across the screen:

<Box>
  <MuxPlayer
    playbackId="9SxUWslZVnYSaV5wp6M66Jd9dUG8ol3Qk2xeMmIVHjs"
    metadata={{ video_title: 'Cylinder movement' }}
    preferPlayback="mse"
    primaryColor="#e5e7eb"
    accentColor="#60889a"
  />
</Box>

Each of the three sides of the cylinder is filled with its own flat texture image (a camera projection). I call each of these surface regions a *facet*. Each texture moves across the screen to track a particular point in its facet, and orients itself to (the projection of) a vector in the facet’s transformation space.

<Img src='placement.png'/>

The shading network is generated based on an input image, which specifies all the parameters of the shader. To create this image, I start by painting unique colors on the model’s UV map to specify the boundaries of the facets. Then within each facet, I add patterns of specially-colored pixels that specify which texture files to use, how the projections should be oriented to follow the <span class="lining">3D</span> surface, and how much to blur between facets. My software then interprets that image to generate the shading network. Here’s the image that generated the bird’s shader:

<Img src='bird explanation.png'/>

## Process

I developed this system over months of testing and critique, and it ended up growing to several thousand lines of code. Some major parts of the process included:
- Creating an interface on top of [PyMEL](https://help.autodesk.com/cloudhelp/2022/JPN/Maya-Tech-Docs/PyMel/) that allows me to deal with shading networks in an object-oriented fashion: a superclass whose subclasses represent different types of shading networks, with functionality to ensure sub-networks are reused whenever possible and to avoid proliferating unused or duplicate nodes
- Doing tests to determine how all the inputs to the <span class="lining">place2dTexture</span> node interact with each other, which is not documented anywhere I could find, and deriving equations to translate the coordinate system I needed for texture placement into the one used by the node
- Writing code to sample nearby points on a surface and translate between  <span class="lining">3D</span> space and UV space, in order to blur a texture image across a surface
- Designing and implementing a user interface for creating and editing these collage shaders: folders and texture files with particular naming conventions, map images as shown above, text files giving more fine-grained control, Maya nodes allowing many controls to be changed and animated in the scene, and scripts for generating and updating all these elements
- Creating a video tutorial and specification document showing others how to use these things